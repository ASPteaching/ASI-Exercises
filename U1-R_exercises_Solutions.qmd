---
title: "Significance and Hypothesis Testing exercises"
author: Alex Sanchez-Pla
date: "`r Sys.Date()`"
format:
    html: 
      toc: true
      toc-depth: 3
      code-fold: false
      fig-width: 8
      fig-height: 6
    pdf:
      toc: true
      number-sections: true
      colorlinks: true
      geometry:
      - top=20mm
      - left=15mm
      papersize: A4
quarto:
    chunk_options:
      echo: true
      cache: false
      prompt: false
      tidy: true
      comment: NA
      message: false
      warning: false
    knit_options:
      width: 75
reference-location: margin
execute:
    echo: true
    message: false
    warning: false
    cache: true
# bibliography: "../StatisticalLearning.bib"
editor_options: 
  chunk_output_type: console
editor: 
  markdown: 
    wrap: 72
---

# Problem 1

The following figures (Cushny and Peebles' data), are quoted quote by R.A. Fisher ${ }^{1}$ from a "Student's" paper, and show the result of an experiment with ten patients on the effect of two supposedly soporific drugs, $A$ and $B$, in producing sleep.

The last column gives a controlled comparison of the efficacy of the two drugs as soporifics,
(a) Propose and apply a test of significance to help decide if both drugs can be considered to have the same soporific effect.
(b) Answer the previous question assuming that the researchers had decide to record only the sign of the difference, but not the numerical value.
(c) Answer the first question assuming that soporific A and B were not tested on the same subjects but, instead on two independent (not matched) groups of subjects.

|Patient| A | B | Difference (B - A). |
| :---: | :---: | :---: | :---: |
| 1 | +0.7 | +1.9 | +1.2 |
| 2 | -0.6 | +0.8 | +2.4 |
| 3 | -0.2 | +1.1 | +1.3 |
| 4 | -1.2 | +0.1 | +1.3 |
| 5 | -0.1 | -0.1 | 0.0 |
| 6 | +3.4 | +4.4 | +1.0 |
| 7 | +3.7 | +5.5 | +1.8 |
| 8 | +0.8 | +1.6 | +0.8 |
| 9 | 0.0 | +4.6 | +4.6 |
| 10 | +2.0 | +3.4 | +1.4 |
| Mean $(\bar{x})$ | +0.75 | +2.33 | +1.58 |

Table 1: Additional Hours of Sleep galned by the Use OF TWO TESTED DRUGS


```{r}
drugA <- c(0.7,-0.6,-0.2,-1.2,-0.1,3.4,3.7, 0.8,0  ,2.0)
drugB <- c(1.9,0.8 ,1.1, 0.1 ,-0.1,4.4,5.5, 1.6,4.6,3.4)
BvsA <- drugB-drugA
```

If we compute observed statistics for each test and then the associated p-values we obtain:

## Paired samples with numerical values

Here we can state the null hypothesis as: $H_0: \mu_D = 0$

We can rely on a student's T statistic, tha, as a corollary of Fisher's Theorem, is known to follow a $t_n-1$ distribution.
$$
\frac{\overline{X}-\mu}{S/\sqrt{n}}\sim t_{n-1}, \text{where: }  S^2=\frac{1}{n-1}\sum_{i=1}^n (X_i-\overline{X})^2.
$$

If we compute the observed value of the test statistic yields: $\tilde t_{obs}=3.91$.

The p-value is defined as $P[T \geq \tilde t_{obs}| H_0] = P[t_{n-1}\tilde t_{obs}| H_0]$

This can be computed in r as: 

```{r}
pt(3.91,9,lower.tail=FALSE)
```

The p-value is very small so it is very unlikely that the observed difference is due to chance which leads us to decide $H_0$ is not acceptable, that is, _there is a significant difference between the drugs_.

## Paired samples. Only signs

Assume we have paired samples and only the signs of the differences

In that case, although we still aim at determining if the drugs have the same effect we can only work with the "number of positive signs".

The statistic "$\mathrm{N}=$ \# of positive signs" in a sample of $n$ observations where the probability of obtaining a positive sign is $p$ follows a binomial distribution:

$$
N_{n, p} \sim B(n, p)
$$

Now the null hypothesis can be stated as: $H_{0}: p=1 / 2$ which means that under this null hypothesis

$$
N_{n . p} \sim \operatorname{Bin}(n=10, p=0.5)
$$

Now, given that we he observed 9 positive signs, the observed value of the statistic is $\tilde{n}_{\text {obs }}=9$ and the p-value can be computed as:

$$
P\left[N_{n, p} \geq \tilde{n}_{\text {obs }} \mid H_{0}\right]=P\left[N_{10,0.5} \geq \tilde{n}_{\text {obs }}\right]=p(N=9)+p(N=10)
$$

This can be computed using R as:
```{r}
p10<- dbinom( 10,10,0.5)
p9<- dbinom (9,10,0.5)
p9+p10
```

The p-value is still small (though not so much as in the previous case) so it is unlikely that the observed difference is due to chance which leads us to decide $H_{0}$ is not acceptable, that is, there is a significant difference between the drugs.

Notice that in this case, the strength of evidence against $H_{0}$ reflected by the p-value is smaller, which is reasonable given that we have less information about how the data deviate from the hypothesis.


## Independent samples

Assume samples are independent and only the signs of the differences

If for whatever reason the drugs had been tested on distinct patients, the question about if the drugs have the same effect may be re-stated, for instance as: $H_{0}: \mu_{A}=\mu_{B}$.

In this case we may, again, rely on a statistic whose distribution is known as a corollary of Fisher's theorem.

Given two independent simple random samples:

$$
X_{1}, X_{2}, \ldots, X_{n_{1}} \stackrel{i i d}{\sim} N\left(\mu_{1}, \sigma_{1}\right) \quad Y_{1}, Y_{2}, \ldots, Y_{n_{2}} \stackrel{i i d}{\sim} N\left(\mu_{2}, \sigma_{2}\right)
$$

The statistic

$$
\frac{\bar{X}-\bar{Y}-\left(\mu_{1}-\mu_{2}\right)}{\sqrt{\left(n_{1}-1\right) S_{1}^{2} / \sigma_{1}^{2}+\left(n_{2}-1\right) S_{2}^{2} / \sigma_{2}^{2}}} \sqrt{\frac{n_{1}+n_{2}-2}{\sigma_{1}^{2} / n_{1}+\sigma_{2}^{2} / n_{2}}}
$$

is distributed as a Student's $t$ with $n_{1}+n_{2}-2$ degrees of freedom. Under the assumption that $\sigma_{1}^{2}=\sigma_{2}^{2}$ and $n_{1}=n_{2}, \sigma^{2}$ cancels out and the statistic can be computed for the sample.

Computing the value of the statistic from the sample yields: $\tilde{t}_{\text {obs}}= 1.80$ and using R the p-value can be computed as:

```{r}
pt (q=1.80, df=18, lower.tail=FALSE)
```

Notice that this p-value can lead to the temptation to discuss significance with respect to a threshold, which should be avoided! Instead it is preferable to notice that there is not much evidence leading to accept there is a significant difference between the drugs.


## A Hypothesis testing approach

### Paired samples with values

$$
H_0: \mu_D = 0; \quad H_1: \mu_D > 0
$$
Student's T-test is the optimal test for this procedure:

```{r}
t.test(BvsA, alternative = "greater")
```

## Paired samples with signs

$$
H_0: \# \text{positive signs} = \# \text{negative signs}
$$
There is no optimal test for this problem but the signs tests or bintest provides a good approximation.

```{r}
binom.test (9,10)
```

## Independent samples

Under the assumption that variances are equal the two-sample t-test provides an optimal solution for this problem

$$
H_0: \mu_A = \mu_B; \quad H_0: \mu_A < \mu_B;
$$

```{r}
t.test(drugB,drugA, alternative = "greater", var.equal=TRUE)
```




# Problem 2
## (a) Type I error probability.

```{r}
n <- 100
p <- .5
Type.I.error.prob <- 
  1 - (  pnorm((60.5 - n*p)/sqrt(n*p*(1-p))) 
       - pnorm((39.5 - n*p)/sqrt(n*p*(1-p))))
print(Type.I.error.prob)
```
## (b) Plot the power function.

```{r, out.width="80%"}
n <- 100
p <- seq(.01,.99,by=.01)
power.p <- 
  1 - (  pnorm((60.5 - n*p)/sqrt(n*p*(1-p))) 
       - pnorm((39.5 - n*p)/sqrt(n*p*(1-p))))

plot(p,power.p,type="l")
abline(v=.5,col=8)
```

## The continuity correction

See [this intuitive eplanation](https://www.drdawnwright.com/continuity-correction-filling-the-cracks/)


\newpage

# Problem 4

<!-- % de Chiara & Hesterberg, exemple  8.15 -->
A team of researchers plans a study to see if a certain drug can increase the speed at which mice move through a maze. An average decrease of
2 seconds through the maze would be considered effective, so the researchers would like to have a good chance of detecting a change this large or larger. Would 20 mice be a large enough sample? Assume the standard deviation is $\sigma = 3$ sec. and that the researchers will use a significance level of $\alpha = 0.05$.


<!-- ```{r} -->
<!-- library(ggplot2) -->
<!-- base <- ggplot() + xlim(0, 20) -->
<!-- base + -->
<!--   geom_function(aes(colour = "H0 : speed = 12"), fun = dnorm, args = list(mean = 12, sd = 2)) + -->
<!--   geom_function(aes(colour = "H11: speed = 11"), fun = dnorm, args = list(mean = 11, sd = 2)) + -->
<!--   geom_function(aes(colour = "H12: speed = 10"), fun = dnorm, args = list(mean = 10, sd = 2)) + -->
<!--   geom_function(aes(colour = "H13: speed =  8"), fun = dnorm, args = list(mean = 8, sd = 2)) -->

<!-- ``` -->

```{r, echo=FALSE, out.width="90%"}
knitr::include_graphics("images/Exercise_1_2_3.png")
```

```{r}
pow<- power.t.test(n=20,
             delta=2,
             sd=3,
             sig.level=0.05, 
             power=NULL,
             type="one.sample",
             alternative="one.sided")
show(pow)

```

Notice that ther is a small difference between the analytical solution and the one using the `power`function because, in the first case we are working with the unrealistic assumption that $\sigma$ is known. The second case (using R) assumes it is unknown and estimated.

\newpage

# Problem 5

<!-- % de Chiara & Hesterberg, exemple  8.16 -->

Suppose the researchers in the previous example want a 95\% chance of rejecting $H_0:\, \mu = 0$ at $\alpha = 0.01$ if the true change is a 1.5 sec. decrease in time. What is the smallest number of mice that should be included in the study? 


```{r, echo=FALSE, out.width="90%"}
knitr::include_graphics("images/Exercise_1_2_4a.png")
```

```{r, echo=FALSE, out.width="90%"}
knitr::include_graphics("images/Exercise_1_2_4b.png")
```

```{r, echo=FALSE, out.width="90%"}
knitr::include_graphics("images/Exercise_1_2_4c.png")
```

Using R:

```{r}
power.t.test(n=NULL,
             delta=1.5,
             sd=3,
             sig.level=0.01, 
             power=0.95,
             type="one.sample",
             alternative="one.sided")
```

As in the previous exercise there is adifference in results due to the unrealistic assumption that $\sigma$ is known in the first case.

\newpage

# Problem 7

The Poisson distribution is discrete, that's why we cannot obtain critical regions having an exact significance level of say $\alpha= 0.05$ or $\alpha= 0.01$ ,
Instead, we iterate the computation until we find the value that defines a critical region with size $\leq \alpha$

## (b)
```{r}
k<-0:20
(alpha.0.k <- (1-ppois(k,10)) )
```

## (c)
```{r}
k<-1:10
(alpha.0.k <- ppois(k-1,10) )
```

<!-- # Problem 9 -->

<!-- ```{r} -->
<!-- x <- seq(-3,3,by=.1) -->
<!-- f1 <- exp(-.5*x^2)/sqrt(2*pi) -->
<!-- f2 <- .5*exp(-abs(x)) -->
<!-- plot(x,f1, ylim=c(0,.5), type="l",  col=4, lwd=2, -->
<!--      ylab = "f(x)", main="Testing N(0,1) against Double Exponential") -->
<!-- lines(x,f2, lty=2, col=3, lwd=2) -->

<!-- x0 <- -1 -->
<!-- lines(c(x0,x0),c(0,exp(-.5*x0^ 2)/(2*pi)^.5), lty=2, col=2, lwd=2) -->
<!-- x0 <- 1 -->
<!-- lines(c(x0,x0),c(0,exp(-.5*x0^ 2)/(2*pi)^.5), lty=2, col=2, lwd=2) -->
<!-- abline(h=0,v=0,col=8) -->
<!-- ``` -->

<!-- ## (b) -->
<!-- ```{r} -->
<!-- eta.0 <- 2*(pnorm(-2)) -->
<!-- eta.1 <- exp(-2) -->
<!-- c(eta.0, eta.1) -->
<!-- ``` -->

<!-- ## (c) -->
<!-- ```{r} -->
<!-- eta.0 <- 1 - 2*(pnorm(3/2)-pnorm(1/2)) -->
<!-- eta.1 <- 1 - (exp(-1/2)-exp(-3/2)) -->
<!-- c(eta.0, eta.1) -->
<!-- ``` -->

# Problem 9

## Permutation tests with R

```{r}
z <- c(94, 197, 16, 38, 99, 141, 23)
y <- c(52, 104, 146, 10, 51, 30, 40, 27, 46)
```

We start by computing the _oberved difference in means_

# Calculating the mean and measuring the difference

```{r}
mean(z) ; length(z)
mean(y) ; length(y)
(diffMeans0 <- mean(z) - mean(y))
```

Now, let us perform a two-sided permutation test using the following steps:

1. Let us combine the two datasets into a single dataset.
2. Randomly assign each data point into either z or y, although we need to maintain the original sample size (n=7) for Z and (n=9) for y.
3. After randomization, calculate the relevant statistic by taking the difference between mean(Zi) and mean(Yi).
4. Repeat the steps above until we have 10000 statistics.

```{r}
combined_data <- c(z, y) # combines the data
set.seed(123) # set seed for reproducibility
null_dist <- c() # declaring a vector to contain the null distributions

# performs randomization at least 100000
for (i in 1:100000) {
  shuffled_data <- sample(combined_data)  # randomly shuffles the data
  shuffled_z <- shuffled_data[1:7] # assigns the first seven points to Z
  shuffled_y <- shuffled_data[8:16]  # assigns the last nine points to y
  null_dist[i] <- mean(shuffled_z) - mean(shuffled_y)
}
hist(null_dist)
```



5. Add the numbers of statistics that are equal to or greater the previously computed difference in means `diffMeans0`. 

6. Calculate the p-value of the permutation test by dividing the sum from step 5 by 10000 (the number of randomization performed).

```{r}
(p_value <- (sum(null_dist >= diffMeans0) + sum(null_dist <= -diffMeans0))/length(null_dist))
```

